{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業目標]\n",
    "持續接觸有關機器學習的相關專案與最新技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "透過觀察頂尖公司的機器學習文章，來了解各公司是怎麼應用機器學習在實際的專案上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業]\n",
    "今天的作業希望大家能夠看看全球機器學習巨頭們在做的機器學習專案。以 google 為例，下圖是 Google 內部專案使用機器學習的數量，隨著時間進展，現在早已超過 2000 個專案在使用機器學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn-images-1.medium.com/max/800/1*U_L8qI8RmYS-MOBrYvXhSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "底下幫同學整理幾間知名企業的 blog 或機器學習網站 (自行搜尋也可)，這些網站都會整理最新的機器學習專案或者是技術文章，請挑選一篇文章閱讀並試著回答\n",
    "1. 專案的目標？ (要解決什麼問題）\n",
    "2. 使用的技術是？ (只需知道名稱即可，例如：使用 CNN 卷積神經網路做影像分類)\n",
    "3. 資料來源？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Google AI blog](https://ai.googleblog.com/)\n",
    "- [Facebook Research blog](https://research.fb.com/blog/)\n",
    "- [Apple machine learning journal](https://machinelearning.apple.com/)\n",
    "- [機器之心](https://www.jiqizhixin.com/)\n",
    "- [雷鋒網](http://www.leiphone.com/category/ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. anchor-free模型移植到移動端或嵌入式設備，對單階段檢測模型三大模塊（Head、Neck、Backbone）進行輕量化，得到模型大小僅1.8m、速度超快的輕量級模型NanoDet-m。\n",
    "\n",
    "2-1. 該模型具備以下優勢：\n",
    "* 超輕量級：模型文件大小僅1.8m；\n",
    "* 速度超快：在移動ARM CPU 上的速度達到97fps（10.23ms）；\n",
    "* 訓練友好：GPU 內存成本比其他模型低得多。GTX1060 6G 上的Batch-size 為80 即可運行；\n",
    "* 方便部署：提供了基於ncnn 推理框架的C++ 實現和Android demo。\n",
    "\n",
    "2-2. 模型架構優化:\n",
    "* 損失函數 : 使用了李翔等人提出的Generalized Focal Loss 損失函數。該函數能夠去掉FCOS 的Centerness 分支，省去這一分支上的大量卷積，從而減少檢測頭的計算開銷，非常適合移動端的輕量化部署。\n",
    "* 檢測頭輕量化 : FCOS 系列使用了共享權重的檢測頭，即對FPN 出來的多尺度Feature Map 使用同一組卷積預測檢測框，然後每一層使用一個可學習的Scale 值作為係數，對預測出來的框進行縮放。這麼做的好處是能夠將檢測頭的參數量降低為不共享權重狀態下的1/5。在檢測頭上使用了Group Normalization（GN）作為歸一化方式，GN對比BN（Batch Normalization）有很多好處，但是卻有一個缺點：BN在推理時能夠將其歸一化的參數直接融合進卷積中，可以省去這一步計算，而GN則不行。為了能夠節省歸一化操作的時間，項目作者選擇將GN替換為BN。\n",
    "* FPN 層改進 : 選擇完全去掉PAN中的所有捲積，只保留從骨幹網絡特徵提取後的1x1卷積來進行特徵通道維度的對齊，上採樣和下採樣均使用插值來完成。與YOLO 使用的concatenate 操作不同，項目作者選擇將多尺度的Feature Map 直接相加，使整個特徵融合模塊的計算量變得非常小。\n",
    "* 骨幹網絡 : 選擇使用ShuffleNetV2 1.0x 作為骨幹網絡，他去掉了該網絡的最後一層卷積，並且抽取8、16、32 倍下採樣的特徵輸入到PAN 中做多尺度的特徵融合。\n",
    "3. 機器之心 - https://www.jiqizhixin.com/articles/2020-11-24-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
